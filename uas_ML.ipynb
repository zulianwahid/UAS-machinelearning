{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjC270gleM0Ea4VKonmSq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zulianwahid/UAS-machinelearning/blob/main/uas_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSOR BASIC"
      ],
      "metadata": {
        "id": "w7g8Soy6eW9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "x = torch.empty(1)\n",
        "print(x)\n",
        "x = torch.empty(3)\n",
        "print(x)\n",
        "x = torch.empty(2,3)\n",
        "print(x)\n",
        "x = torch.empty(2,2,3)\n",
        "print(x)\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "print(x.size())\n",
        "print(x.dtype)\n",
        "\n",
        "\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "\n",
        "print(x.dtype)\n",
        "\n",
        "\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "\n",
        "z = x + y\n",
        "\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0])\n",
        "print(x[1, :])\n",
        "print(x[1,1])\n",
        "\n",
        "\n",
        "print(x[1,1].item())\n",
        "\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    y = torch.ones_like(x, device=device)\n",
        "    x = x.to(device)\n",
        "    z = x + y\n",
        "\n",
        "    z.to(\"cpu\")\n"
      ],
      "metadata": {
        "id": "PMsek1-HeW45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUTOGRAD"
      ],
      "metadata": {
        "id": "s9mmC9fHeW0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "\n",
        "\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "SRjeXl_9eWwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BACK PROPAGATION"
      ],
      "metadata": {
        "id": "wsXoGpv_eWsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "\n",
        "w.grad.zero_()\n",
        "\n"
      ],
      "metadata": {
        "id": "tGINLtHaeWn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gradientdescent_manually"
      ],
      "metadata": {
        "id": "bGXPWMWAeWjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.mean(2*x*(y_pred - y))\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "    y_pred = forward(X)\n",
        "\n",
        "\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "id": "UtkDDbDoeWfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gradientdescent_auto"
      ],
      "metadata": {
        "id": "b_od1nwkeWbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "    y_pred = forward(X)\n",
        "\n",
        "\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "\n",
        "    l.backward()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "id": "W4pvZbu3eWW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss_and_optimizer"
      ],
      "metadata": {
        "id": "dRudyw_feWS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "    y_predicted = forward(X)\n",
        "\n",
        "\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "\n",
        "    l.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "id": "ryaEQRdPeWOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_loss_and_ optimizer"
      ],
      "metadata": {
        "id": "sKBiWv6oeWKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "    y_predicted = model(X)\n",
        "\n",
        "\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "\n",
        "    l.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters()\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "id": "M6k0_jqTeWGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# linear_regression"
      ],
      "metadata": {
        "id": "TFSM9FAaeWCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pwWUh9fheV96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logistic_regression"
      ],
      "metadata": {
        "id": "65btOU9jeV5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "id": "eyXdIdk8eV1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATALOADER"
      ],
      "metadata": {
        "id": "Rs680pOieVxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:])\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]])\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "\n",
        "dataset = WineDataset()\n",
        "\n",
        "\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=3,\n",
        "                                           shuffle=True)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "id": "Wv0etT97eVtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformers"
      ],
      "metadata": {
        "id": "OSU-h8s5eVoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "class ToTensor:\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "ACdFM-pVeVkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# softmax_and_crossentropy"
      ],
      "metadata": {
        "id": "51zpunfZeVfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0)\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9],\n",
        "    [1.2, 0.1, 0.3],\n",
        "    [0.3, 2.2, 0.2]])\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "UHh8-zVteVaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# activation_functions"
      ],
      "metadata": {
        "id": "eJRFWyNAgOcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "jPwuFMFwgOI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot_activations"
      ],
      "metadata": {
        "id": "qu7pkHldgOA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,100)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(y,sigmoid(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Sigmoid Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-2, -1, 0, 1, 2])\n",
        "\n",
        "plt.ylim(-2, 2)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "tanh = lambda x: 2*sigmoid(2*x)-1\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,100)\n",
        "\n",
        "plt.plot(y,tanh(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('TanH Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "relu = lambda x: np.where(x>=0, x, 0)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,relu(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('ReLU')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "leakyrelu = lambda x: np.where(x>=0, x, 0.1*x)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,leakyrelu(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Leaky ReLU')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "\n",
        "bstep = lambda x: np.where(x>=0, 1, 0)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,bstep(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Step Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-2, -1, 0, 1, 2])\n",
        "\n",
        "plt.ylim(-2, 2)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "id": "CQCG_9tagN6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# feedforward"
      ],
      "metadata": {
        "id": "SoUAZvD9gNy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "id": "FGAWwswXgO-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cnn"
      ],
      "metadata": {
        "id": "hW2SgYsThFyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "YGvNC4NihGGQ",
        "outputId": "1f5f8cd9-6a97-4139-b614-e4b311b33696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 99252999.70it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3003\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.2978\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.2892\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.2812\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.2933\n",
            "Epoch [1/5], Step [12000/12500], Loss: 2.0195\n",
            "Epoch [2/5], Step [2000/12500], Loss: 1.9475\n",
            "Epoch [2/5], Step [4000/12500], Loss: 2.1027\n",
            "Epoch [2/5], Step [6000/12500], Loss: 1.8371\n",
            "Epoch [2/5], Step [8000/12500], Loss: 2.2092\n",
            "Epoch [2/5], Step [10000/12500], Loss: 1.5109\n",
            "Epoch [2/5], Step [12000/12500], Loss: 2.0765\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.6506\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.9440\n",
            "Epoch [3/5], Step [6000/12500], Loss: 1.6063\n",
            "Epoch [3/5], Step [8000/12500], Loss: 1.7736\n",
            "Epoch [3/5], Step [10000/12500], Loss: 1.3363\n",
            "Epoch [3/5], Step [12000/12500], Loss: 1.3867\n",
            "Epoch [4/5], Step [2000/12500], Loss: 1.1770\n",
            "Epoch [4/5], Step [4000/12500], Loss: 1.6533\n",
            "Epoch [4/5], Step [6000/12500], Loss: 1.1553\n",
            "Epoch [4/5], Step [8000/12500], Loss: 1.7616\n",
            "Epoch [4/5], Step [10000/12500], Loss: 1.3568\n",
            "Epoch [4/5], Step [12000/12500], Loss: 2.0865\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.2665\n",
            "Epoch [5/5], Step [4000/12500], Loss: 0.4549\n",
            "Epoch [5/5], Step [6000/12500], Loss: 1.2564\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.5355\n",
            "Epoch [5/5], Step [10000/12500], Loss: 1.5304\n",
            "Epoch [5/5], Step [12000/12500], Loss: 1.9252\n",
            "Finished Training\n",
            "Accuracy of the network: 49.45 %\n",
            "Accuracy of plane: 55.5 %\n",
            "Accuracy of car: 59.5 %\n",
            "Accuracy of bird: 25.9 %\n",
            "Accuracy of cat: 35.8 %\n",
            "Accuracy of deer: 30.3 %\n",
            "Accuracy of dog: 38.8 %\n",
            "Accuracy of frog: 65.4 %\n",
            "Accuracy of horse: 64.8 %\n",
            "Accuracy of ship: 59.0 %\n",
            "Accuracy of truck: 59.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transfer_learning"
      ],
      "metadata": {
        "id": "iK0s6fEZhHQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "id": "xZ7olevAhG9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensor board**"
      ],
      "metadata": {
        "id": "u7fXdXhp-biA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYtYyh0P5gvP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "\n",
        "\n",
        "\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE LOAD"
      ],
      "metadata": {
        "id": "b2T0ueQCqN-1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2VxewukqN3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE))\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 90,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" SAVING ON GPU/CPU\n",
        "\n",
        "# 1) Save on GPU, Load on CPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "\n",
        "# 2) Save on GPU, Load on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "\n",
        "# Note: Be sure to use the .to(torch.device('cuda')) function\n",
        "# on all model inputs, too!\n",
        "\n",
        "# 3) Save on CPU, Load on GPU\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "\n",
        "# This loads the model to a given GPU device.\n",
        "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "S0l3hGPqnx5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}